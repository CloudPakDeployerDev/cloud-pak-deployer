resource  "ibm_resource_instance" "{{generator.attributes.name | replace("-", "_") }}" {
    name     = "{{generator.attributes.name}}-cos"
    plan     = "standard"
    location = "global"
    service  = "cloud-object-storage"
}


resource "ibm_container_vpc_cluster" "{{generator.attributes.name | replace("-", "_") }}" {
    name = "{{generator.attributes.name}}"
    cos_instance_crn = ibm_resource_instance.{{generator.attributes.name | replace("-", "_") }}.id
    kube_version = "{{generator.attributes.ocp_version}}_openshift"
    flavor       = "{{generator.attributes.worker_flavour}}"
    entitlement  = "cloud_pak"
    vpc_id       = ibm_is_vpc.{{generator.attributes.infrastructure.vpc_name | replace("-", "_") }}.id
    worker_count = "{{ ((generator.attributes.number_of_workers) / (generator.attributes.infrastructure.get('subnets',[]) | length)) | int }}"
    resource_group_id = data.ibm_resource_group.thisresourcegroup.id

{% for item in generator.attributes.infrastructure.get('subnets',[]) %}
{% set subnet = generator.config.subnet | selectattr("name", "equalto", item) | list | first %}
    zones {
        subnet_id = ibm_is_subnet.{{item | replace("-", "_") }}.id
        name      = "{{subnet.zone}}"
    }

{% endfor %}
}

{% for item in generator.attributes.openshift_storage %}
{% if item.storage_type == "ocs" %}
resource "ibm_container_vpc_worker_pool" "{{generator.attributes.name | replace("-", "_") }}_ocs" {
    cluster           = "{{generator.attributes.name }}"
    worker_pool_name  = "{{generator.attributes.name }}-{{item.ocs_storage_label}}"
    flavor       = "{{generator.attributes.worker_flavour}}"
    vpc_id       = ibm_is_vpc.{{generator.attributes.infrastructure.vpc_name | replace("-", "_") }}.id
    worker_count      = "{{ (3 / (generator.attributes.infrastructure.get('subnets',[]) | length)) | int }}"
    resource_group_id = data.ibm_resource_group.thisresourcegroup.id

    labels = {
        "roks-storage" = "{{ item.ocs_storage_label }}"
    }

{% for item in generator.attributes.infrastructure.get('subnets',[]) %}
{% set subnet = generator.config.subnet | selectattr("name", "equalto", item) | list | first %}
    zones {
        subnet_id = ibm_is_subnet.{{item | replace("-", "_") }}.id
        name      = "{{subnet.zone}}"
    }

{% endfor %}

    depends_on = [ibm_container_vpc_cluster.{{ generator.attributes.name | replace("-", "_") }}]
}
{% endif %}

{% if item.storage_type == "pwx" %}

data "ibm_container_cluster_config" "{{generator.attributes.name | replace("-", "_") }}" {
  cluster_name_id   = "{{generator.attributes.name}}"
  resource_group_id = data.ibm_resource_group.thisresourcegroup.id
  config_dir        = "{{status_dir}}/terraform/kubeconfig"
  depends_on = [ibm_container_vpc_cluster.{{ generator.attributes.name | replace("-", "_") }}]
}

provider "kubernetes" {
  config_path = data.ibm_container_cluster_config.{{generator.attributes.name | replace("-", "_") }}.config_file_path
}

//locals used only in openshift.tf
locals {
  kube_config_path = data.ibm_container_cluster_config.{{generator.attributes.name | replace("-", "_") }}.config_file_path
  worker_nodes     = {{generator.attributes.number_of_workers}} // Number of workers
  enable           = true

  // Storage parameters
  install_storage  = true
  storage_capacity = {{item.pwx_storage_size}} 
  storage_iops     = {{item.pwx_storage_iops}}
  storage_profile  = "{{item.pwx_storage_profile}}"

  // Portworx parameters
  region              = "{{ibm_cloud_region}}"
  cluster_id          = "{{generator.attributes.name}}"
  unique_id           = "{{generator.attributes.name}}"

  create_external_etcd = true
  etcd_username        = "portworxetcduser"
  etcd_password        = "portworX3tcdpassw0rd"
  // Defaulted.  Don't change
  etcd_secret_name = "px-etcd-certs"
}


data "ibm_container_vpc_cluster" "{{generator.attributes.name | replace("-", "_") }}" {
  depends_on = [ibm_container_vpc_cluster.{{ generator.attributes.name | replace("-", "_") }}]  
  count = local.enable ? 1 : 0
  name = local.cluster_id
  resource_group_id = data.ibm_resource_group.thisresourcegroup.id
}

data "ibm_container_vpc_cluster_worker" "{{generator.attributes.name | replace("-", "_") }}" {
  count = local.enable ? local.worker_nodes : 0
  cluster_name_id   = local.cluster_id
  resource_group_id = data.ibm_resource_group.thisresourcegroup.id
  worker_id         = length(data.ibm_container_vpc_cluster.{{generator.attributes.name | replace("-", "_") }}) > 0 ? data.ibm_container_vpc_cluster.{{generator.attributes.name | replace("-", "_") }}[0].workers[count.index] : 0
}

data "ibm_iam_auth_token" "{{generator.attributes.name | replace("-", "_") }}" {}

# ibm_is_subnet is currently bugged. On a run, it can error with an expi.workers[count.index]red or bad token. A subsequent rerun fixes this, 
# but this script should run the first time without any problems.
data "ibm_is_subnet" "{{generator.attributes.name | replace("-", "_") }}" {
  count = local.enable ? local.worker_nodes : 0
  identifier = length(data.ibm_container_vpc_cluster_worker.{{generator.attributes.name | replace("-", "_") }}) > 0 ? data.ibm_container_vpc_cluster_worker.{{generator.attributes.name | replace("-", "_") }}[count.index].network_interfaces[0].subnet_id : 0
}

# Create a block storage volume per worker.
resource "ibm_is_volume" "{{generator.attributes.name | replace("-", "_") }}" {
  depends_on = [
    data.ibm_is_subnet.{{generator.attributes.name | replace("-", "_") }}
  ]

  count = local.enable && local.install_storage ? local.worker_nodes : 0 
  
  capacity = local.storage_capacity
  iops = local.storage_profile == "custom" ? local.storage_iops : null
  name = length(data.ibm_container_vpc_cluster.{{generator.attributes.name | replace("-", "_") }}) > 0 ? "${local.unique_id}-pwx-${split("-", data.ibm_container_vpc_cluster.{{generator.attributes.name | replace("-", "_") }}[0].workers[count.index])[4]}" : "${local.unique_id}-pwx"
  profile = local.storage_profile
  resource_group = data.ibm_resource_group.thisresourcegroup.id
  zone = length(data.ibm_is_subnet.{{generator.attributes.name | replace("-", "_") }}) > 0 ? data.ibm_is_subnet.{{generator.attributes.name | replace("-", "_") }}[count.index].zone : ""
}

# locals {
#   worker_volume_map = zipmap(data.ibm_container_vpc_cluster_worker.this.*.id, ibm_is_volume.{{generator.attributes.name | replace("-", "_") }}.*.id)
# }

# Attach block storage to worker
resource "null_resource" "volume_attachment_{{generator.attributes.name | replace("-", "_") }}" {
  # count = length(data.ibm_container_vpc_cluster_worker.worker)
  count = local.enable && local.install_storage ? local.worker_nodes : 0 

  depends_on = [
    ibm_is_volume.{{generator.attributes.name | replace("-", "_") }}
  ]
  # for_each = local.worker_volume_map
  
  triggers = {
    volume = length(ibm_is_volume.{{generator.attributes.name | replace("-", "_") }}) > 0 ? ibm_is_volume.{{generator.attributes.name | replace("-", "_") }}[count.index].id : 0
    worker = length(data.ibm_container_vpc_cluster_worker.{{generator.attributes.name | replace("-", "_") }}) > 0 ? data.ibm_container_vpc_cluster_worker.{{generator.attributes.name | replace("-", "_") }}[count.index].id : 0
  }

  provisioner "local-exec" {
    environment = {
      IBMCLOUD_API_KEY  = var.ibmcloud_api_key
      TOKEN             = data.ibm_iam_auth_token.{{generator.attributes.name | replace("-", "_") }}.iam_access_token
      REGION            = local.region
      RESOURCE_GROUP_ID = data.ibm_resource_group.thisresourcegroup.id
      CLUSTER_ID        = local.cluster_id
      WORKER_ID         = length(data.ibm_container_vpc_cluster_worker.{{generator.attributes.name | replace("-", "_") }}) > 0 ? data.ibm_container_vpc_cluster_worker.{{generator.attributes.name | replace("-", "_") }}[count.index].id : 0
      VOLUME_ID         = length(ibm_is_volume.{{generator.attributes.name | replace("-", "_") }}) > 0 ? ibm_is_volume.{{generator.attributes.name | replace("-", "_") }}[count.index].id : 0      
    }

    interpreter = ["/bin/bash", "-c"]
    command     = file("./scripts/volume_attachment.sh")
  }

  # this breaks beyond terraform 0.12 because destroy provisioners are not allowed to reference other resources
  # check with ibm terraform providers team for a volume_attachment resource
  # provisioner "local-exec" {
  #   when = destroy
  #   environment = {
  #     IBMCLOUD_API_KEY  = local.ibmcloud_api_key
  #     TOKEN             = data.ibm_iam_auth_token.{{generator.attributes.name | replace("-", "_") }}.iam_access_token
  #     REGION            = local.region
  #     RESOURCE_GROUP_ID = data.ibm_resource_group.thisresourcegroup.id
  #     CLUSTER_ID        = local.cluster_id
  #     WORKER_ID         = length(data.ibm_container_vpc_cluster_worker.this) > 0 ? data.ibm_container_vpc_cluster_worker.this[count.index].id : 0
  #     VOLUME_ID         = length(ibm_is_volume.this) > 0 ? ibm_is_volume.{{generator.attributes.name | replace("-", "_") }}[count.index].id : 0
  #   }
  
  #   interpreter = ["/bin/bash", "-c"]
  #   command     = file("./scripts/volume_attachment_destroy.sh")
  # }
}

#############################################
# Create 'Databases for Etcd' service instance
#############################################
resource "ibm_database" "etcd_{{generator.attributes.name | replace("-", "_") }}" {
  count = local.enable && local.create_external_etcd ? 1 : 0
  location = local.region
  members_cpu_allocation_count = 9
  members_disk_allocation_mb = 393216
  members_memory_allocation_mb = 24576
  name = "${local.unique_id}-pwx-etcd"
  plan = "standard"
  resource_group_id = data.ibm_resource_group.thisresourcegroup.id
  service = "databases-for-etcd"
  service_endpoints = "private"
  version = "3.3"
  users {
    name = local.etcd_username
    password = local.etcd_password
  }
}

# find the object in the connectionstrings list in which the `name` is local.etcd_username
locals {
  etcd_user_connectionstring = (local.create_external_etcd ?
                                ibm_database.etcd_{{generator.attributes.name | replace("-", "_") }}[0].connectionstrings[index(ibm_database.etcd_{{generator.attributes.name | replace("-", "_") }}[0].connectionstrings[*].name, local.etcd_username)] :
                                null)
}

resource "kubernetes_secret" "etcd_{{generator.attributes.name | replace("-", "_") }}" {
  depends_on = [ibm_container_vpc_cluster.{{ generator.attributes.name | replace("-", "_") }}]
  count = local.enable && local.create_external_etcd ? 1 : 0

  metadata {
    name = local.etcd_secret_name
    namespace = "kube-system"
  }

  data = {
    "ca.pem" = base64decode(local.etcd_user_connectionstring.certbase64)
    username = local.etcd_username
    password = local.etcd_password
  }
  
}

##################################
# Install Portworx on the cluster
##################################
resource "ibm_resource_instance" "portworx_{{generator.attributes.name | replace("-", "_") }}" {
  depends_on = [
    null_resource.volume_attachment_{{generator.attributes.name | replace("-", "_") }},
    kubernetes_secret.etcd_{{generator.attributes.name | replace("-", "_") }}
  ]


  count = local.enable ? 1 : 0

  name              = "${local.unique_id}-pwx-service"
  service           = "portworx"
  plan              = "px-enterprise"
  location          = local.region
  resource_group_id = data.ibm_resource_group.thisresourcegroup.id

  tags = [
    "clusterid:${local.cluster_id}",
  ]

  parameters = {
    apikey           = var.ibmcloud_api_key
    cluster_name     = "pwx"
    clusters         = local.cluster_id
    etcd_endpoint    = ( local.create_external_etcd ?
      "etcd:https://${local.etcd_user_connectionstring.hosts[0].hostname}:${local.etcd_user_connectionstring.hosts[0].port}"
      : null
    )
    etcd_secret      = local.create_external_etcd ? local.etcd_secret_name : null
    internal_kvdb    = local.create_external_etcd ? "external" : "internal"
    portworx_version = "Portworx: 2.7.2 , Stork: 2.6.2"
    secret_type      = "k8s"
  }

//  provisioner "local-exec" {
//    environment = {
//      KUBECONFIG = local.kube_config_path
//    }
//    interpreter = ["/bin/bash", "-c"]
//    command     = file("./scripts/portworx_wait_until_ready.sh")
//  }
  /*
  #
  # Currently, deleting the portworx service instance does not uninstall portworx
  # from the cluster.
  #
  */

}
{% endif %}

{% endfor %}
