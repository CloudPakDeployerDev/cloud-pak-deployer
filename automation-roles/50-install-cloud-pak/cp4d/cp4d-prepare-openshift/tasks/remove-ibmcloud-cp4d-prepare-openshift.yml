---
- set_fact:
    reload_workers: False
    reboot_workers: False

- name: Create private registries configuration (ImageContentSourcePolicy) for Cloud Pak for Data with private registry
  block:
    - name: Check if ConfigMap cp4d-icsp-registries exists
      shell: "oc get configmap -n kube-system | grep -i '^cp4d-icsp-registries' | wc -l"
      register: oc_icsp_cm_exists
    - name: Create private registries configuration
      template:
        src: cp4d-icsp-registries-conf.j2
        dest: "{{ cp4d_automation_temp_dir.path }}/cp4d-icsp-registries.conf"
    - name: Create ConfigMap cp4d-icsp-registries
      shell: |
        if ! oc get configmap -n kube-system cp4d-icsp-registries;then
          oc create configmap -n kube-system cp4d-icsp-registries \
            --from-file={{ cp4d_automation_temp_dir.path }}/cp4d-icsp-registries.conf
        fi
    - name: Set data for secret
      shell: |
        oc set data configmap/cp4d-icsp-registries -n kube-system \
          --from-file={{ cp4d_automation_temp_dir.path }}/cp4d-icsp-registries.conf
    - name: Generate DaemonSet to set the private registry configuration for all nodes
      template:
        src: cp4d-icsp-registries-conf-ds.j2
        dest: "{{ cp4d_automation_temp_dir.path }}/cp4d-icsp-registries-conf-ds.yaml"
    - name: Create or replace DaemonSet cp4d-icsp-registries-conf-ds
      shell: |
        if oc get ds -n kube-system cp4d-icsp-registries-conf-ds;then
          oc delete ds -n kube-system cp4d-icsp-registries-conf-ds
        fi
        oc apply -f {{ cp4d_automation_temp_dir.path }}/cp4d-icsp-registries-conf-ds.yaml
  when: not (use_entitled_registry | bool)

- name: Set global pull secret for specified private registry
  block:
    - name: Get credential for container registry {{ current_cp4d_cluster.image_registry_name }} if it exists in the vault
      include_role: 
        name: vault-get-secret
      vars:
        secret_name: "image-registry-{{ current_cp4d_cluster.image_registry_name }}"
        secret_group: "{{ environment_name }}"  

    - name: Validate if container registry credentials secret is available
      fail: msg="Container registry credentials secret image-registry-{{ current_cp4d_cluster.image_registry_name }} from group {{ environment_name }} is empty"
      when: secret_value== ""

    - name: Create temporary directory to hold current pull secret content
      tempfile:
        state: directory
      register: pull_secret_dir
    - name: Extract the global pull secret
      shell: |
        oc extract secret/pull-secret -n openshift-config --confirm --to={{ pull_secret_dir.path }}
    - name: Set the global pull secret
      shell: |
        cat {{ pull_secret_dir.path }}/.dockerconfigjson | \
          jq --arg private_registry "{{ private_registry_url }}" \
            --arg pull_secret $(echo -n "{{ secret_value }}" | base64 -w0) \
            '.auths += {($private_registry): {"auth": $pull_secret, "email": "not-used"}}' \
            > {{ pull_secret_dir.path }}/newdockerconfigjson
        oc set data secret/pull-secret -n openshift-config \
          --from-file=.dockerconfigjson={{ pull_secret_dir.path }}/newdockerconfigjson

  when: not (use_entitled_registry | bool)

- name: Set global pull secret for entitled registry
  block:

    - name: Create temporary directory to hold current pull secret content
      tempfile:
        state: directory
      register: pull_secret_dir
    - name: Extract the global pull secret
      shell: |
        oc extract secret/pull-secret -n openshift-config --confirm --to={{ pull_secret_dir.path }}
    - name: Set the global pull secret
      shell: |
        cat {{ pull_secret_dir.path }}/.dockerconfigjson | \
          jq --arg registry "{{ entitled_registry }}" \
            --arg pull_secret $(echo -n "cp:{{ ibm_cp_entitlement_key }}" | base64 -w0) \
            '.auths += {($registry): {"auth": $pull_secret, "email": "not-used"}}' \
            > {{ pull_secret_dir.path }}/newdockerconfigjson
        oc set data secret/pull-secret -n openshift-config \
          --from-file=.dockerconfigjson={{ pull_secret_dir.path }}/newdockerconfigjson

  when: (use_entitled_registry | bool)

# Create or update daemonset to update pull secret for nodes
- name: Create temporary directory to hold current global pull secret content
  tempfile:
    state: directory
  register: pull_secret_dir
- name: Extract the global pull secret
  shell: |
    oc extract secret/pull-secret -n openshift-config --confirm --to={{ pull_secret_dir.path }}
- name: Create secret for DaemonSet
  shell: |
    if ! oc get secret -n kube-system cp4d-pull-secret;then
      oc create secret generic cp4d-pull-secret -n kube-system > /dev/null 2>&1
    fi
- name: Set data for secret
  shell: |
    oc set data secret/cp4d-pull-secret -n kube-system \
      --from-file=newdockerconfigjson={{ pull_secret_dir.path }}/.dockerconfigjson
- name: Generate DaemonSet to set the current pull secret for all nodes
  template:
    src: cp4d-pull-secret-ds.j2
    dest: "{{ cp4d_automation_temp_dir.path }}/cp4d-pull-secret-ds.yaml"
- name: Create or replace DaemonSet cp4d-pull-secret-ds
  shell: |
    if oc get ds -n kube-system cp4d-pull-secret-ds;then
      oc delete ds -n kube-system cp4d-pull-secret-ds
    fi
    oc apply -f {{ cp4d_automation_temp_dir.path }}/cp4d-pull-secret-ds.yaml

# Set kernel parameters via Tuned
- name: Check if the Tuned {{ cp4d_tuned_name }} exists
  shell: "oc get Tuned -n openshift-cluster-node-tuning-operator | grep -i '^{{ cp4d_tuned_name }}' | wc -l"
  register: oc_tuned_exists

- name: Configure Tuned {{ cp4d_tuned_name }}
  block:
    - name: Create Tuned yaml
      template:
        src: cp4d-tuned.j2
        dest: "{{ cp4d_automation_temp_dir.path }}/cp4d-tuned.yaml"
    - name: Create Tuned cp4d_ipc
      shell: "oc apply -f {{ cp4d_automation_temp_dir.path }}/cp4d-tuned.yaml"
    - set_fact:
        reload_workers: True
  when: oc_tuned_exists.stdout == "0"

# TODO: Should we process other worker pools too? Probably all workers pools except OCS should be in scope.
- name: Get the worker nodes for the default worker pool
  command: |
    ibmcloud oc workers --cluster {{ current_cp4d_cluster.openshift_cluster_name }} \
      --worker-pool default --output json
  register: default_workers
  when: reload_workers

# TODO: Remove debug
- name: Show workers from default worker pool
  debug:
    var: default_workers
  when: reload_workers

- name: Get worker names
  set_fact:
    worker_ids: "{{ default_workers.stdout | from_json | json_query(get_ids) | list }}"
  vars:
    get_ids: "[*].id"
  when: reload_workers

- set_fact:
    number_of_workers: "{{ worker_ids | length }}"
  when: reload_workers

# - fail:
#     msg: "DO NOT REPLACE WORKERS!"

# - name: Reload (replace) the workers for cluster {{ current_cp4d_cluster.openshift_cluster_name }}
#   command: |
#     ibmcloud oc worker replace --cluster {{ current_cp4d_cluster.openshift_cluster_name }} --worker {{ worker_item }} -f 
#   loop: "{{ worker_ids }}"
#   loop_control:
#     loop_var: worker_item
#   when: reload_workers

# - name: Wait for 3 minutes to allow workers to start being replaced
#   pause:
#     minutes: 3
#   when: reload_workers

# - name: Wait for {{ number_of_workers }} workers for cluster {{ current_cp4d_cluster.openshift_cluster_name }} to be redeployed
#   shell: |
#     ibmcloud oc workers --cluster {{ current_cp4d_cluster.openshift_cluster_name }} --worker-pool default --output json | \
#       jq -r '.[] | select(.lifecycle.actualState=="deployed").lifecycle.actualState' | \
#       wc -l
#   register: deployed_workers
#   retries: 60
#   delay: 60
#   until: deployed_workers.stdout == number_of_workers
#   when: reload_workers
#   vars:
#     ansible_callback_diy_runner_retry_msg: >-
#       {%- set result = ansible_callback_diy.result.output -%}
#       {%- set retries_left = result.retries - result.attempts -%}
#       Retrying: {{ ansible_callback_diy.task.name }} ({{ retries_left }} Retries left) ...



